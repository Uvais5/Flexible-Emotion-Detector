# ðŸŽ­ Flexible Emotion Detector

Detect human emotions from **video ðŸŽ¦**, **audio ðŸŽ§**, or **text ðŸ’¬** â€” all in one flexible and interactive Streamlit app.

<p align="center">
  <img src="docs/front_view.png" alt="App screenshot" width="640">
</p>

---

## ðŸ§© Project Overview

Flexible Emotion Detector is a **multi-modal emotion recognition system** that adapts to different input types â€” video, audio, or text. It extracts emotional cues from:

- **Facial expressions** in videos
- **Speech signals** in audio
- **Words and phrases** in spoken or written text

This tool integrates deep learning models for vision, audio, and NLP to give a unified emotion prediction experience. It is ideal for applications like affective computing, mood analysis, and emotional insight extraction in humanâ€“AI interaction.

---

## ðŸ’¡ Problem It Solves

- âœ… Users often donâ€™t have the same input format â€” some only provide audio, some video, others just typed or spoken text.
- âœ… Most emotion models work on only **one modality**.
- âœ… This system adapts to **whatever input is available** â€” making it useful in real-world settings like:
  - Virtual therapy & mood tracking
  - Voice assistants
  - Social media content analysis
  - Human behavior research

---

## âœ¨ Key Features
| Modality | What Happens | Model |
|----------|--------------|-------|
| **Face** | Picks the emotion that appears most often across all faces in the video. | CNN (FER-2013) |
| **Speech** | Extracts MFCC features â†’ LSTM â†’ emotion from vocal tone. | Audio model (`emotion_audio_model.h5`) |
| **Text** | Speech-to-text â†’ EmoRoBERTa sentiment classifier. | Hugging Face pipeline |

Switch modalities on/off in the sidebar. Upload **video (mp4)**, **audio (wav/mp3)**, or just paste text.

---

## ðŸš€ Quick Start (local)

```bash
# clone
git clone https://github.com/Uvais5/Flexible-Emotion-Detector.git
cd Flexible-Emotion-Detector

# create env & install deps
python -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate
pip install -r requirements.txt

# launch app
streamlit run new_main.py         # open browser at http://localhost:8501

